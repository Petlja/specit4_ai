Хиперпараметри
==============

Видели смо да је у алгоритму к-најближих суседа потребно да унапред фиксирамо вредност броја к, као и да различити избори доводе до различитих 
закључака. Како да знамо коју вредност баш да одаберемо? Ово питање прати и све друге алгоритме машинског учења у којима се појављују неке 
вредности које унапред треба да дефинишемо. Њих зовемо **хиперпараметрима** или **метапараметрима**. 

Поменули смо да приликом поделе скупа података увек издвајамо скуп за тренирање, скуп за тестирање и скуп за валидацију. Скуп за валидацију до 
сада нисмо користили. Он нам је заправо потребан кадгод у нашем алгоритму учења фигуришу неки хиперпараметри. Прича коју ћемо поделити важи за 
све алгоритме, али ћемо наставити да користимо алгоритам к-најближих суседа. 

Вратимо се на питање како да одаберемо најбољу вредност хиперпараметра к. Природно је да помислимо: пробаћемо више вредности на пример, све 
бројеве од 1 до 10, па ћемо одабрати најбољу вредност! Ово ћемо заправо и урадити али ћемо јако водити рачуна о томе где опробавамо колико је 
наш избор добар. Ако то будемо радили над скупом за тестирање огрешићемо се о златно правило машинског учења о строгој раздвојености скупа за 
тестирање и развоја модела: употребићемо скуп за тестирање да одлучимо која је најбоља вредност хиперпараметра к, а онда ћемо, када обучимо модел, 
опет искористити скуп за тестирање да оценимо колико је добар! Сложићеш се да то и нема баш пуно смисла! 

Коректно је да урадимо следеће: испробаваћемо које вредности хиперпараметара су најбоље на скупу за валидацију. Тај скуп не дели информације ни 
са скупом за тренирање ни са скупом за тестирање па ће допринети објективности наших закључака.  Сада када смо то установили, можемо да се бацимо 
на посао одређивања најбоље вредности хиперпараметра. 

За сваку од вредности хиперпараметра к коју желимо да пробамо, посебно ћемо обучити модел на скупу за тренирање и израчунати његову меру квалитета, 
рецимо F1 меру, на валидационом скупу. Добијене вредности можемо да прикажемо графички тако што ћемо дуж x-осе поставити различите вредности 
параметра к, а дуж y-осе вредности F1 мере. По правилу бирамо ону вредност хиперпараметра к за коју добијамо најбољу вредност мере квалитета 
на валидационом скупу. То се на графику обично види у облику пика.


Приказ F1 мере на скупу за валидацију
**(ТОДО)**


Када у алгоритму учења фигурише више хиперпараметара циљ је пронаћи најбољу комбинацију хиперпараметара. Њу, такође, одређујемо на основу скупа за 
валидацију пратећи успшешност модела и ловећи комбинацију која даје најбољу вредност мере квалитета. Невоља је што овај поступак за велики број 
хиперпараметара може да буде доста спор: рецимо, ако желимо да испитамо 10 различитих вредности броја к и 3 различите функције растојања имамо 
заправо 10x3=30 различитих комбинација па морамо да обучимо и оценимо 30 различитих модела. 
